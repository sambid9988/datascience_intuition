# datascience_intuition

1>How decision trees split while doing regression?
https://www.quora.com/How-does-a-decision-tree-select-a-cutpoint-if-the-feature-is-continuous

2>gamma parameter in svm?
https://www.youtube.com/watch?v=m2a2K4lprQw

3>Best explanation for gradient boosting trees?
https://www.youtube.com/watch?v=j034-r3O2Cg&t=2s

4>cosine similarity and cosine distance?
https://www.youtube.com/watch?v=ieMjGVYw9ag

5> how to reduce predictors in logistic regression?
https://stats.stackexchange.com/questions/224614/how-to-reduce-variables-in-logistic-regression

6>relation between logarithm and exponents?
https://www.mathsisfun.com/algebra/exponents-logarithms.html

7>ridge regression and lasso regression calculation?
https://www.youtube.com/watch?v=5asL5Eq2x0A&t=439s
https://www.youtube.com/watch?v=jbwSCwoT51M

8>why R2 increases with increase in predictors?
https://stats.stackexchange.com/questions/207717/why-does-r2-grow-when-more-predictor-variables-are-added-to-a-model

9>Support vector regression?
https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/

10> Accuracy vs F1 Score?
https://medium.com/analytics-vidhya/accuracy-vs-f1-score-6258237beca2

11> eigen values and eigen vectors?
https://medium.com/fintechexplained/what-are-eigenvalues-and-eigenvectors-a-must-know-concept-for-machine-learning-80d0fd330e47

12>purpose of softmax?
https://www.quora.com/How-does-the-softmax-classification-layer-of-a-neural-network-work


13> Random Variable, Probability , Probability Mass function, Probability Density Function?
https://www.britannica.com/science/statistics/Random-variables-and-probability-distributions


14> Maximum likelihood estimation?
https://www.youtube.com/watch?v=BfKanl1aSG0

15>Boxplots?
https://www.simplypsychology.org/boxplots.html

16>ANOVA,ANCOVA,MANOVA?
http://www.statsmakemecry.com/smmctheblog/stats-soup-anova-ancova-manova-mancova

17>Attention models?
https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html
https://blog.floydhub.com/attention-mechanism/
https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/

18>Transformer?
http://jalammar.github.io/illustrated-transformer/ 
https://www.youtube.com/watch?v=TQQlZhbC5ps

19>GPT,BERT,ELMo and Co?
http://jalammar.github.io/illustrated-bert/
http://jalammar.github.io/illustrated-gpt2/
https://www.youtube.com/watch?v=xI0HHN5XKDo&t=4s

20>word2vec?
http://jalammar.github.io/illustrated-word2vec/

21>cnn explained easy?
https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480

22>batch normalisation?
https://mlexplained.com/2018/01/10/an-intuitive-explanation-of-why-batch-normalization-really-works-normalization-in-deep-learning-part-1/

23>invoice region of interest extraction?
https://stackoverflow.com/questions/56278094/extracting-data-from-invoices-in-pdf-or-image-format/63400793#63400793

24>inception network?
https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202#:~:text=The%20Inception%20network%20was%20an,Designing%20CNNs%20in%20a%20nutshell.

25>Linear regression OLS vs gradient descent?
https://towardsdatascience.com/linear-regression-simplified-ordinary-least-square-vs-gradient-descent-48145de2cf76

26>Local Minima vs Global?
https://www.mathworks.com/help/optim/ug/local-vs-global-optima.html#:~:text=A%20local%20minimum%20of%20a,at%20all%20other%20feasible%20points.

27>Noise?
https://elitedatascience.com/overfitting-in-machine-learning

28>Slope in machine Learning?
https://www.mathsisfun.com/algebra/line-equation-point-slope.html#:~:text=What%20About%20y%20%3D%20mx%20%2B%20b,line%20crosses%20the%20y%2Daxis.

29>Does gradient descent always converge?
https://www.quora.com/Does-Gradient-Descent-Algo-always-converge-to-the-global-minimum



